{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "#import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'train.csv')\n",
    "test = pd.read_csv(r'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0     1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1     1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2     1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3     1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4     1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
       "1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
       "1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
       "1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
       "1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub  ...         120        0    NaN  MnPrv   \n",
       "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "4            HLS    AllPub  ...         144        0    NaN    NaN   \n",
       "...          ...       ...  ...         ...      ...    ...    ...   \n",
       "1454         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1457         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0      6    2010        WD         Normal  \n",
       "1           Gar2   12500      6    2010        WD         Normal  \n",
       "2            NaN       0      3    2010        WD         Normal  \n",
       "3            NaN       0      6    2010        WD         Normal  \n",
       "4            NaN       0      1    2010        WD         Normal  \n",
       "...          ...     ...    ...     ...       ...            ...  \n",
       "1454         NaN       0      6    2006        WD         Normal  \n",
       "1455         NaN       0      4    2006        WD        Abnorml  \n",
       "1456         NaN       0      9    2006        WD        Abnorml  \n",
       "1457        Shed     700      7    2006        WD         Normal  \n",
       "1458         NaN       0     11    2006        WD         Normal  \n",
       "\n",
       "[1459 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],test.loc[:,'MSSubClass':'SaleCondition']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1454         160       RM         21.0     1936   Pave   NaN      Reg   \n",
       "1455         160       RM         21.0     1894   Pave   NaN      Reg   \n",
       "1456          20       RL        160.0    20000   Pave   NaN      Reg   \n",
       "1457          85       RL         62.0    10441   Pave   NaN      Reg   \n",
       "1458          60       RL         74.0     9627   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1454         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0       2    2008        WD         Normal  \n",
       "1            NaN       0       5    2007        WD         Normal  \n",
       "2            NaN       0       9    2008        WD         Normal  \n",
       "3            NaN       0       2    2006        WD        Abnorml  \n",
       "4            NaN       0      12    2008        WD         Normal  \n",
       "...          ...     ...     ...     ...       ...            ...  \n",
       "1454         NaN       0       6    2006        WD         Normal  \n",
       "1455         NaN       0       4    2006        WD        Abnorml  \n",
       "1456         NaN       0       9    2006        WD        Abnorml  \n",
       "1457        Shed     700       7    2006        WD         Normal  \n",
       "1458         NaN       0      11    2006        WD         Normal  \n",
       "\n",
       "[2919 rows x 79 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model regression . fit\n",
    "# model lasso . fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'price'}>,\n",
       "        <AxesSubplot:title={'center':'log(price + 1)'}>]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#features more normal\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "prices = pd.DataFrame({\"price\":train[\"SalePrice\"], \"log(price + 1)\":np.log1p(train[\"SalePrice\"])})\n",
    "prices.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12.247699\n",
       "1       12.109016\n",
       "2       12.317171\n",
       "3       11.849405\n",
       "4       12.429220\n",
       "          ...    \n",
       "1455    12.072547\n",
       "1456    12.254868\n",
       "1457    12.493133\n",
       "1458    11.864469\n",
       "1459    11.901590\n",
       "Name: SalePrice, Length: 1460, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"SalePrice\"] #define target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
       "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
       "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
       "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
       "       'MoSold', 'YrSold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>5.283204</td>\n",
       "      <td>6.561031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>6.753438</td>\n",
       "      <td>6.753438</td>\n",
       "      <td>6.751101</td>\n",
       "      <td>...</td>\n",
       "      <td>7.444833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.886532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652489</td>\n",
       "      <td>7.141245</td>\n",
       "      <td>7.141245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.141245</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.700444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>6.188264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.075346</td>\n",
       "      <td>6.825460</td>\n",
       "      <td>6.825460</td>\n",
       "      <td>6.765039</td>\n",
       "      <td>...</td>\n",
       "      <td>7.488294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.262680</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.379897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.293419</td>\n",
       "      <td>6.629363</td>\n",
       "      <td>6.869014</td>\n",
       "      <td>6.629363</td>\n",
       "      <td>...</td>\n",
       "      <td>7.448916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>5.609472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>5.860786</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.196444</td>\n",
       "      <td>7.044033</td>\n",
       "      <td>7.044033</td>\n",
       "      <td>6.960348</td>\n",
       "      <td>...</td>\n",
       "      <td>7.695758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.262690</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>5.081404</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>7.568896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>...</td>\n",
       "      <td>6.996681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>5.081404</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>7.546974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.533389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.686975</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>...</td>\n",
       "      <td>6.996681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>5.081404</td>\n",
       "      <td>9.903538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.110696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.110696</td>\n",
       "      <td>7.110696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.110696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.163315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>4.454347</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>9.253591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.823046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.356108</td>\n",
       "      <td>6.816736</td>\n",
       "      <td>6.878326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.878326</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.552508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>9.172431</td>\n",
       "      <td>4.553877</td>\n",
       "      <td>6.632002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.476464</td>\n",
       "      <td>6.904751</td>\n",
       "      <td>6.904751</td>\n",
       "      <td>6.912743</td>\n",
       "      <td>...</td>\n",
       "      <td>7.601402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.252273</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage   LotArea  MasVnrArea  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       4.110874     4.189655  9.042040    5.283204    6.561031         0.0   \n",
       "1       3.044522     4.394449  9.169623    0.000000    6.886532         0.0   \n",
       "2       4.110874     4.234107  9.328212    5.093750    6.188264         0.0   \n",
       "3       4.262680     4.110874  9.164401    0.000000    5.379897         0.0   \n",
       "4       4.110874     4.442651  9.565284    5.860786    6.486161         0.0   \n",
       "...          ...          ...       ...         ...         ...         ...   \n",
       "1454    5.081404     3.091042  7.568896    0.000000    0.000000         0.0   \n",
       "1455    5.081404     3.091042  7.546974    0.000000    5.533389         0.0   \n",
       "1456    3.044522     5.081404  9.903538    0.000000    7.110696         0.0   \n",
       "1457    4.454347     4.143135  9.253591    0.000000    5.823046         0.0   \n",
       "1458    4.110874     4.317488  9.172431    4.553877    6.632002         0.0   \n",
       "\n",
       "      BsmtUnfSF  TotalBsmtSF  1stFlrSF  2ndFlrSF  ...  GrLivArea  \\\n",
       "0      5.017280     6.753438  6.753438  6.751101  ...   7.444833   \n",
       "1      5.652489     7.141245  7.141245  0.000000  ...   7.141245   \n",
       "2      6.075346     6.825460  6.825460  6.765039  ...   7.488294   \n",
       "3      6.293419     6.629363  6.869014  6.629363  ...   7.448916   \n",
       "4      6.196444     7.044033  7.044033  6.960348  ...   7.695758   \n",
       "...         ...          ...       ...       ...  ...        ...   \n",
       "1454   6.304449     6.304449  6.304449  6.304449  ...   6.996681   \n",
       "1455   5.686975     6.304449  6.304449  6.304449  ...   6.996681   \n",
       "1456   0.000000     7.110696  7.110696  0.000000  ...   7.110696   \n",
       "1457   6.356108     6.816736  6.878326  0.000000  ...   6.878326   \n",
       "1458   5.476464     6.904751  6.904751  6.912743  ...   7.601402   \n",
       "\n",
       "      BsmtHalfBath  KitchenAbvGr  WoodDeckSF  OpenPorchSF  EnclosedPorch  \\\n",
       "0         0.000000      0.693147    0.000000     4.127134       0.000000   \n",
       "1         0.693147      0.693147    5.700444     0.000000       0.000000   \n",
       "2         0.000000      0.693147    0.000000     3.761200       0.000000   \n",
       "3         0.000000      0.693147    0.000000     3.583519       5.609472   \n",
       "4         0.000000      0.693147    5.262690     4.442651       0.000000   \n",
       "...            ...           ...         ...          ...            ...   \n",
       "1454      0.000000      0.693147    0.000000     0.000000       0.000000   \n",
       "1455      0.000000      0.693147    0.000000     3.218876       0.000000   \n",
       "1456      0.000000      0.693147    6.163315     0.000000       0.000000   \n",
       "1457      0.693147      0.693147    4.394449     3.496508       0.000000   \n",
       "1458      0.000000      0.693147    5.252273     3.891820       0.000000   \n",
       "\n",
       "      3SsnPorch  ScreenPorch  PoolArea   MiscVal  \n",
       "0           0.0          0.0       0.0  0.000000  \n",
       "1           0.0          0.0       0.0  0.000000  \n",
       "2           0.0          0.0       0.0  0.000000  \n",
       "3           0.0          0.0       0.0  0.000000  \n",
       "4           0.0          0.0       0.0  0.000000  \n",
       "...         ...          ...       ...       ...  \n",
       "1454        0.0          0.0       0.0  0.000000  \n",
       "1455        0.0          0.0       0.0  0.000000  \n",
       "1456        0.0          0.0       0.0  0.000000  \n",
       "1457        0.0          0.0       0.0  6.552508  \n",
       "1458        0.0          0.0       0.0  0.000000  \n",
       "\n",
       "[2919 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[skewed_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling NA's with the mean of the column:\n",
    "all_data = all_data.fillna(all_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating matrices for sklearn:\n",
    "X_train = all_data[:train.shape[0]]\n",
    "X_test = all_data[train.shape[0]:]\n",
    "y = train.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>5.283204</td>\n",
       "      <td>6.561031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.886532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>6.188264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.262680</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.379897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.860786</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>5.081404</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>7.568896</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>5.081404</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>7.546974</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.533389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>5.081404</td>\n",
       "      <td>9.903538</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.110696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>4.454347</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>9.253591</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.823046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>9.172431</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>4.553877</td>\n",
       "      <td>6.632002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows × 288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       4.110874     4.189655  9.042040            7            5       2003   \n",
       "1       3.044522     4.394449  9.169623            6            8       1976   \n",
       "2       4.110874     4.234107  9.328212            7            5       2001   \n",
       "3       4.262680     4.110874  9.164401            7            5       1915   \n",
       "4       4.110874     4.442651  9.565284            8            5       2000   \n",
       "...          ...          ...       ...          ...          ...        ...   \n",
       "1454    5.081404     3.091042  7.568896            4            7       1970   \n",
       "1455    5.081404     3.091042  7.546974            4            5       1970   \n",
       "1456    3.044522     5.081404  9.903538            5            7       1960   \n",
       "1457    4.454347     4.143135  9.253591            5            5       1992   \n",
       "1458    4.110874     4.317488  9.172431            7            5       1993   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw  \\\n",
       "0             2003    5.283204    6.561031         0.0  ...               0   \n",
       "1             1976    0.000000    6.886532         0.0  ...               0   \n",
       "2             2002    5.093750    6.188264         0.0  ...               0   \n",
       "3             1970    0.000000    5.379897         0.0  ...               0   \n",
       "4             2000    5.860786    6.486161         0.0  ...               0   \n",
       "...            ...         ...         ...         ...  ...             ...   \n",
       "1454          1970    0.000000    0.000000         0.0  ...               0   \n",
       "1455          1970    0.000000    5.533389         0.0  ...               0   \n",
       "1456          1996    0.000000    7.110696         0.0  ...               0   \n",
       "1457          1992    0.000000    5.823046         0.0  ...               0   \n",
       "1458          1994    4.553877    6.632002         0.0  ...               0   \n",
       "\n",
       "      SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
       "0                0             0            1                      0   \n",
       "1                0             0            1                      0   \n",
       "2                0             0            1                      0   \n",
       "3                0             0            1                      1   \n",
       "4                0             0            1                      0   \n",
       "...            ...           ...          ...                    ...   \n",
       "1454             0             0            1                      0   \n",
       "1455             0             0            1                      1   \n",
       "1456             0             0            1                      1   \n",
       "1457             0             0            1                      0   \n",
       "1458             0             0            1                      0   \n",
       "\n",
       "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "1454                      0                     0                     0   \n",
       "1455                      0                     0                     0   \n",
       "1456                      0                     0                     0   \n",
       "1457                      0                     0                     0   \n",
       "1458                      0                     0                     0   \n",
       "\n",
       "      SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                        1                      0  \n",
       "1                        1                      0  \n",
       "2                        1                      0  \n",
       "3                        0                      0  \n",
       "4                        1                      0  \n",
       "...                    ...                    ...  \n",
       "1454                     1                      0  \n",
       "1455                     0                      0  \n",
       "1456                     0                      0  \n",
       "1457                     1                      0  \n",
       "1458                     1                      0  \n",
       "\n",
       "[2919 rows x 288 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphas=[0.1] \n",
    "cv_ridge = [rmse_cv(Ridge(alpha =alpha)).mean() \n",
    "            for alpha in alphas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE Value - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13777538277187865]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE Value - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = LassoCV(alphas = [0.1]).fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20921930047608214"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv(model_lasso).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed that ridge performed better for alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Ridge\n",
    "alphas=np.arange(5, 15, 1).tolist() #running on alpha from 5 to 15 at a 1 point interval\n",
    "cv_ridge = [rmse_cv(Ridge(alpha =alpha)).mean() \n",
    "            for alpha in alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12462456247627858"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_index=cv_ridge.index(min(cv_ridge)) #min cv see for index\n",
    "cv_ridge[min_index] #this is minimum cv score we could achieve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas[min_index] #min CV achieved at alpha = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.859303278561697, tolerance: 0.018912592760396085\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.258099494383032, tolerance: 0.01800219138548883\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.095507695528681, tolerance: 0.018373605848561597\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.830192851556973, tolerance: 0.019008081403702633\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.703112019074069, tolerance: 0.01881061188370518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1714: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(X, y)\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.153e+00, tolerance: 2.328e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.408086015859652, tolerance: 0.014608206095799353\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3429133294122835, tolerance: 0.014601004078052359\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4384767145872672, tolerance: 0.015531757542978097\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.8278641008923273, tolerance: 0.015448874096282393\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.662871714576852, tolerance: 0.015453647710308875\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1714: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(X, y)\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.859e+00, tolerance: 1.891e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2536434100549343, tolerance: 0.014421032323759136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.9707363365353388, tolerance: 0.013878761882709149\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.087257530374444, tolerance: 0.014621128652612829\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.348621517954655, tolerance: 0.01453514652569633\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0780217762180655, tolerance: 0.014544304735976838\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1714: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(X, y)\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.258e+00, tolerance: 1.800e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0790672649188764, tolerance: 0.014791078401076713\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0144529990702154, tolerance: 0.014455328041034693\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.9529042356278694, tolerance: 0.014416323383021182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.068283089476779, tolerance: 0.014911027581501767\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.9778136058683344, tolerance: 0.014914232105412309\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1714: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(X, y)\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.096e+00, tolerance: 1.837e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.662638422652776, tolerance: 0.01542865087978492\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7220790268548285, tolerance: 0.015089979013565014\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.1001416961530026, tolerance: 0.014491631155835854\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2917637433675395, tolerance: 0.01546918576152043\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.715049164561293, tolerance: 0.01555239160345648\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1714: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(X, y)\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.830e+00, tolerance: 1.901e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.594857666327016, tolerance: 0.015228754219030277\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.507120575904935, tolerance: 0.014892726351484208\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.8619794229225306, tolerance: 0.014286517661843702\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3364262224156107, tolerance: 0.01528597962708133\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5593446109644447, tolerance: 0.015536468891600251\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1714: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(X, y)\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.703e+00, tolerance: 1.881e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.615471910912783, tolerance: 0.018912592760396085\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.533073026002818, tolerance: 0.01800219138548883\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7976842306456415, tolerance: 0.018373605848561597\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.0641836907517686, tolerance: 0.019008081403702633\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.750804124126514, tolerance: 0.01881061188370518\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.029e+00, tolerance: 2.328e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.624303685919733, tolerance: 0.014608206095799353\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5858037066255313, tolerance: 0.014601004078052359\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0523974121701123, tolerance: 0.015531757542978097\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.446512492581457, tolerance: 0.015448874096282393\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.152278833299417, tolerance: 0.015453647710308875\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.615e+00, tolerance: 1.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.217263913581357, tolerance: 0.014421032323759136\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.443954968474139, tolerance: 0.013878761882709149\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.665566639287204, tolerance: 0.014621128652612829\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0259754795312492, tolerance: 0.01453514652569633\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.585549436782871, tolerance: 0.014544304735976838\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.533e+00, tolerance: 1.800e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3501323179237668, tolerance: 0.014791078401076713\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.822299186863197, tolerance: 0.014455328041034693\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.591417369483983, tolerance: 0.014416323383021182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.80432622344757, tolerance: 0.014911027581501767\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7203334974103153, tolerance: 0.014914232105412309\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.798e+00, tolerance: 1.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.1139795001391075, tolerance: 0.01542865087978492\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.408925106094356, tolerance: 0.015089979013565014\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.038981239741273654, tolerance: 0.014491631155835854\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7046920606635325, tolerance: 0.01546918576152043\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5478921093964022, tolerance: 0.01555239160345648\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.064e+00, tolerance: 1.901e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7779819572060833, tolerance: 0.015228754219030277\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.968267697889652, tolerance: 0.014892726351484208\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.468789047621422, tolerance: 0.014286517661843702\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.108128501993739, tolerance: 0.01528597962708133\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.177128491666036, tolerance: 0.015536468891600251\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.508e-01, tolerance: 1.881e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.672e-02, tolerance: 2.328e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5979311859839189, tolerance: 0.014621128652612829\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8695637627781112, tolerance: 0.015089979013565014\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0784646139311942, tolerance: 0.01546918576152043\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    }
   ],
   "source": [
    "# For Lasso\n",
    "alphas=np.arange(0, 0.001, 0.0001).tolist() #running on alpha from 0 to 0.001 at a 0.0001 point interval\n",
    "lasso_cv=[]\n",
    "alpha_curr=[]\n",
    "for i in alphas:\n",
    "    model_lasso_cv = rmse_cv(LassoCV(alphas=[i]).fit(X_train, y)).mean()\n",
    "    alpha_curr.append(i)\n",
    "    lasso_cv.append(model_lasso_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10675721697744578"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_index=lasso_cv.index(min(lasso_cv)) #min cv see for index\n",
    "lasso_cv[min_index] #this is minimum cv score we could achieve with lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009000000000000001"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_curr[min_index] #min CV achieved at alpha = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'rmse')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#L0 Norm of the coefficients that lasso produces\n",
    "lasso_cv = pd.Series(lasso_cv, index = alphas)\n",
    "lasso_cv.plot(title = \"L0 Norm\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Ridge, we were able to optimize alpha = 10, to get RMSE CV score of 0.127\n",
    "### For Lasso, alpha = 0.0005 to get RMSE CV score of 0.1225 - lower than Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Id\n",
      "- SalePrice\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Lasso_val\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 290 features, but LassoCV is expecting 289 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Now checking predictions - Lasso\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_lasso \u001b[38;5;241m=\u001b[39m LassoCV(alphas \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0005\u001b[39m])\u001b[38;5;241m.\u001b[39mfit(X_train, y)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel_lasso\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:362\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:345\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    343\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 290 features, but LassoCV is expecting 289 features as input."
     ]
    }
   ],
   "source": [
    "#Now checking predictions - Lasso\n",
    "model_lasso = LassoCV(alphas = [0.0005]).fit(X_train, y)\n",
    "model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now checking predictions - Ridge\n",
    "model_ridge = Ridge(alpha=0.1).fit(X_train,y) #0.1 because submitting to kaggle as per step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Id\n",
      "- SalePrice\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Lasso_val\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 290 features, but Ridge is expecting 289 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_ridge\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_ridge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:362\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:345\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    343\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 290 features, but Ridge is expecting 289 features as input."
     ]
    }
   ],
   "source": [
    "pred_ridge=model_ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ridge_df=pd.DataFrame(np.expm1(pred_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xk/szxzvgq138ndv5c88q9xfh1m0000gn/T/ipykernel_78305/2551422627.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['SalePrice']=pred_ridge_df[0]\n",
      "/var/folders/xk/szxzvgq138ndv5c88q9xfh1m0000gn/T/ipykernel_78305/2551422627.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Id'] = X_test.index\n",
      "/var/folders/xk/szxzvgq138ndv5c88q9xfh1m0000gn/T/ipykernel_78305/2551422627.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Id'] += 1461\n"
     ]
    }
   ],
   "source": [
    "X_test['SalePrice']=pred_ridge_df[0]\n",
    "X_test['Id'] = X_test.index\n",
    "X_test['Id'] += 1461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission score=0.135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['Id','SalePrice']].to_csv('submission.csv') #0.135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features to ridge regression | Ensembling and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xk/szxzvgq138ndv5c88q9xfh1m0000gn/T/ipykernel_78305/1276833.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Lasso_val'] = model_lasso.predict(X_train)\n",
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Lasso_val\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 289 features, but Ridge is expecting 288 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model_lasso \u001b[38;5;241m=\u001b[39m LassoCV(alphas \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0005\u001b[39m])\u001b[38;5;241m.\u001b[39mfit(X_train, y)\n\u001b[1;32m      3\u001b[0m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLasso_val\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model_lasso\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m----> 4\u001b[0m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRidge_val\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_ridge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:362\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:345\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    343\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 289 features, but Ridge is expecting 288 features as input."
     ]
    }
   ],
   "source": [
    "model_ridge = Ridge(alpha=10).fit(X_train, y)\n",
    "model_lasso = LassoCV(alphas = [0.0005]).fit(X_train, y)\n",
    "X_train['Lasso_val'] = model_lasso.predict(X_train)\n",
    "X_train['Ridge_val'] = model_ridge.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>Lasso_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>5.283204</td>\n",
       "      <td>6.561031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.244881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.886532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.160932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>6.188264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.294685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.262680</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.379897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.060877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.860786</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.616734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0    4.110874     4.189655  9.042040            7            5       2003   \n",
       "1    3.044522     4.394449  9.169623            6            8       1976   \n",
       "2    4.110874     4.234107  9.328212            7            5       2001   \n",
       "3    4.262680     4.110874  9.164401            7            5       1915   \n",
       "4    4.110874     4.442651  9.565284            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_New  \\\n",
       "0          2003    5.283204    6.561031         0.0  ...             0   \n",
       "1          1976    0.000000    6.886532         0.0  ...             0   \n",
       "2          2002    5.093750    6.188264         0.0  ...             0   \n",
       "3          1970    0.000000    5.379897         0.0  ...             0   \n",
       "4          2000    5.860786    6.486161         0.0  ...             0   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0             0            1                      0                      0   \n",
       "1             0            1                      0                      0   \n",
       "2             0            1                      0                      0   \n",
       "3             0            1                      1                      0   \n",
       "4             0            1                      0                      0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                     0                     0                     1   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   SaleCondition_Partial  Lasso_val  \n",
       "0                      0  12.244881  \n",
       "1                      0  12.160932  \n",
       "2                      0  12.294685  \n",
       "3                      0  12.060877  \n",
       "4                      0  12.616734  \n",
       "\n",
       "[5 rows x 289 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Ridge train predictions\n",
    "model_ridge = Ridge(alpha=10).fit(X_train, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12463006094208148"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv(model_ridge).mean() #RMSE is improved, earlier it was 0.127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train.loc[:,'MSSubClass':'SaleCondition_Partial'], label = y)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "params = {\"max_depth\":2, \"eta\":0.1}\n",
    "model = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.loc[30:,[\"test-rmse-mean\", \"train-rmse-mean\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manvimahajan/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=2, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=360, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)\n",
    "model_xgb.fit(X_train.loc[:,'MSSubClass':'SaleCondition_Partial'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 288, got 290",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_lasso \u001b[38;5;241m=\u001b[39m LassoCV(alphas \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0005\u001b[39m])\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSSubClass\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaleCondition_Partial\u001b[39m\u001b[38;5;124m'\u001b[39m], y)\n\u001b[0;32m----> 2\u001b[0m xgb_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(\u001b[43mmodel_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m lasso_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(model_lasso\u001b[38;5;241m.\u001b[39mpredict(X_test))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:881\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 881\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m    890\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m     \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:2025\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2022\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m         )\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m-> 2025\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2026\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2027\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2028\u001b[0m         )\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _array_interface\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 288, got 290"
     ]
    }
   ],
   "source": [
    "model_lasso = LassoCV(alphas = [0.0005]).fit(X_train.loc[:,'MSSubClass':'SaleCondition_Partial'], y)\n",
    "xgb_preds = np.expm1(model_xgb.predict(X_test))\n",
    "lasso_preds = np.expm1(model_lasso.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"xgb\":xgb_preds, \"lasso\":lasso_preds})\n",
    "predictions.plot(x = \"xgb\", y = \"lasso\", kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using only xgb_preds, model is overfitting. On training RMSE is ~0.1, but on test it is 0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv(model_xgb).mean() #RMSE is improved, earlier it was 0.127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = 0.7*lasso_preds + 0.3*xgb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":preds})\n",
    "# solution.to_csv(\"ridge_sol.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.to_csv('submission.csv') #Score: 0.12299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve upon this XGboost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xk/szxzvgq138ndv5c88q9xfh1m0000gn/T/ipykernel_78305/3511061470.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  all_data['GarageYrBltn'] = abs(all_data['YrSold'] - all_data['GarageYrBlt'])\n",
      "/var/folders/xk/szxzvgq138ndv5c88q9xfh1m0000gn/T/ipykernel_78305/3511061470.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  all_data['YearRemodAddn'] = abs(all_data['YrSold'] - all_data['YearRemodAdd'])\n",
      "/var/folders/xk/szxzvgq138ndv5c88q9xfh1m0000gn/T/ipykernel_78305/3511061470.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  all_data['YearBuiltn'] = abs(all_data['YrSold'] - all_data['YearBuilt'])\n",
      "/var/folders/xk/szxzvgq138ndv5c88q9xfh1m0000gn/T/ipykernel_78305/3511061470.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  all_data['SF'] = all_data['1stFlrSF']+all_data['2ndFlrSF']+all_data['TotalBsmtSF']+all_data['GrLivArea']+all_data['HalfBath']+all_data['FullBath']\n"
     ]
    }
   ],
   "source": [
    "all_data['GarageYrBltn'] = abs(all_data['YrSold'] - all_data['GarageYrBlt'])\n",
    "all_data['YearRemodAddn'] = abs(all_data['YrSold'] - all_data['YearRemodAdd'])\n",
    "all_data['YearBuiltn'] = abs(all_data['YrSold'] - all_data['YearBuilt'])\n",
    "all_data['SF'] = all_data['1stFlrSF']+all_data['2ndFlrSF']+all_data['TotalBsmtSF']+all_data['GrLivArea']+all_data['HalfBath']+all_data['FullBath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>GarageYrBltn</th>\n",
       "      <th>YearRemodAddn</th>\n",
       "      <th>YearBuiltn</th>\n",
       "      <th>SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>5.283204</td>\n",
       "      <td>6.561031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>30.702811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.886532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>23.423735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>6.188264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>30.904253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.262680</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.379897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>91</td>\n",
       "      <td>28.576657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.860786</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>31.744172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>5.081404</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>7.568896</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.886594</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>27.910028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>5.081404</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>7.546974</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.533389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>27.910028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>5.081404</td>\n",
       "      <td>9.903538</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.110696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>22.332088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>4.454347</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>9.253591</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.823046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.886594</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>21.573389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>9.172431</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>4.553877</td>\n",
       "      <td>6.632002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>31.323647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows × 292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       4.110874     4.189655  9.042040            7            5       2003   \n",
       "1       3.044522     4.394449  9.169623            6            8       1976   \n",
       "2       4.110874     4.234107  9.328212            7            5       2001   \n",
       "3       4.262680     4.110874  9.164401            7            5       1915   \n",
       "4       4.110874     4.442651  9.565284            8            5       2000   \n",
       "...          ...          ...       ...          ...          ...        ...   \n",
       "1454    5.081404     3.091042  7.568896            4            7       1970   \n",
       "1455    5.081404     3.091042  7.546974            4            5       1970   \n",
       "1456    3.044522     5.081404  9.903538            5            7       1960   \n",
       "1457    4.454347     4.143135  9.253591            5            5       1992   \n",
       "1458    4.110874     4.317488  9.172431            7            5       1993   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  \\\n",
       "0             2003    5.283204    6.561031         0.0  ...   \n",
       "1             1976    0.000000    6.886532         0.0  ...   \n",
       "2             2002    5.093750    6.188264         0.0  ...   \n",
       "3             1970    0.000000    5.379897         0.0  ...   \n",
       "4             2000    5.860786    6.486161         0.0  ...   \n",
       "...            ...         ...         ...         ...  ...   \n",
       "1454          1970    0.000000    0.000000         0.0  ...   \n",
       "1455          1970    0.000000    5.533389         0.0  ...   \n",
       "1456          1996    0.000000    7.110696         0.0  ...   \n",
       "1457          1992    0.000000    5.823046         0.0  ...   \n",
       "1458          1994    4.553877    6.632002         0.0  ...   \n",
       "\n",
       "      SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                         0                      0                     0   \n",
       "1                         0                      0                     0   \n",
       "2                         0                      0                     0   \n",
       "3                         1                      0                     0   \n",
       "4                         0                      0                     0   \n",
       "...                     ...                    ...                   ...   \n",
       "1454                      0                      0                     0   \n",
       "1455                      1                      0                     0   \n",
       "1456                      1                      0                     0   \n",
       "1457                      0                      0                     0   \n",
       "1458                      0                      0                     0   \n",
       "\n",
       "      SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \\\n",
       "0                        0                     1                      0   \n",
       "1                        0                     1                      0   \n",
       "2                        0                     1                      0   \n",
       "3                        0                     0                      0   \n",
       "4                        0                     1                      0   \n",
       "...                    ...                   ...                    ...   \n",
       "1454                     0                     1                      0   \n",
       "1455                     0                     0                      0   \n",
       "1456                     0                     0                      0   \n",
       "1457                     0                     1                      0   \n",
       "1458                     0                     1                      0   \n",
       "\n",
       "      GarageYrBltn  YearRemodAddn  YearBuiltn         SF  \n",
       "0         5.000000              5           5  30.702811  \n",
       "1        31.000000             31          31  23.423735  \n",
       "2         7.000000              6           7  30.904253  \n",
       "3         8.000000             36          91  28.576657  \n",
       "4         8.000000              8           8  31.744172  \n",
       "...            ...            ...         ...        ...  \n",
       "1454     27.886594             36          36  27.910028  \n",
       "1455     36.000000             36          36  27.910028  \n",
       "1456     46.000000             10          46  22.332088  \n",
       "1457     27.886594             14          14  21.573389  \n",
       "1458     13.000000             12          13  31.323647  \n",
       "\n",
       "[2919 rows x 292 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_data)\n",
    "all_data = pd.DataFrame(scaler.transform(all_data), index = all_data.index, columns = all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>GarageYrBltn</th>\n",
       "      <th>YearRemodAddn</th>\n",
       "      <th>YearBuiltn</th>\n",
       "      <th>SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.419418</td>\n",
       "      <td>-0.020358</td>\n",
       "      <td>-0.103719</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>1.046258</td>\n",
       "      <td>0.896833</td>\n",
       "      <td>1.219420</td>\n",
       "      <td>0.783352</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-1.003156</td>\n",
       "      <td>-0.887271</td>\n",
       "      <td>-1.037932</td>\n",
       "      <td>1.198255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.120845</td>\n",
       "      <td>0.619103</td>\n",
       "      <td>0.146544</td>\n",
       "      <td>-0.063185</td>\n",
       "      <td>2.188279</td>\n",
       "      <td>0.154764</td>\n",
       "      <td>-0.395604</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>0.892570</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>0.047817</td>\n",
       "      <td>0.357618</td>\n",
       "      <td>-0.180699</td>\n",
       "      <td>-0.572342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.419418</td>\n",
       "      <td>0.118440</td>\n",
       "      <td>0.457629</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>0.848965</td>\n",
       "      <td>1.146941</td>\n",
       "      <td>0.658276</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.922312</td>\n",
       "      <td>-0.839391</td>\n",
       "      <td>-0.971991</td>\n",
       "      <td>1.247255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.638691</td>\n",
       "      <td>-0.266348</td>\n",
       "      <td>0.136301</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>-1.859351</td>\n",
       "      <td>-0.682812</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>0.387039</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>3.789876</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>-2.155466</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.881890</td>\n",
       "      <td>0.597020</td>\n",
       "      <td>1.797529</td>\n",
       "      <td>0.681079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.419418</td>\n",
       "      <td>0.769612</td>\n",
       "      <td>0.922662</td>\n",
       "      <td>1.355551</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>0.947203</td>\n",
       "      <td>0.753229</td>\n",
       "      <td>1.440386</td>\n",
       "      <td>0.758231</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.881890</td>\n",
       "      <td>-0.743630</td>\n",
       "      <td>-0.939021</td>\n",
       "      <td>1.451561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1.821276</td>\n",
       "      <td>-3.450727</td>\n",
       "      <td>-2.993401</td>\n",
       "      <td>-1.481920</td>\n",
       "      <td>1.289758</td>\n",
       "      <td>-0.043346</td>\n",
       "      <td>-0.682812</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>-1.418112</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.078033</td>\n",
       "      <td>0.597020</td>\n",
       "      <td>-0.015847</td>\n",
       "      <td>0.518925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1.821276</td>\n",
       "      <td>-3.450727</td>\n",
       "      <td>-3.036401</td>\n",
       "      <td>-1.481920</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>-0.043346</td>\n",
       "      <td>-0.682812</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>0.438541</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>3.789876</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>-2.155466</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>0.249927</td>\n",
       "      <td>0.597020</td>\n",
       "      <td>-0.015847</td>\n",
       "      <td>0.518925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>-1.120845</td>\n",
       "      <td>2.764091</td>\n",
       "      <td>1.586172</td>\n",
       "      <td>-0.772552</td>\n",
       "      <td>1.289758</td>\n",
       "      <td>-0.373528</td>\n",
       "      <td>0.561757</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>0.967785</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>3.789876</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>-2.155466</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>0.654148</td>\n",
       "      <td>-0.647869</td>\n",
       "      <td>0.313858</td>\n",
       "      <td>-0.837880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.915540</td>\n",
       "      <td>-0.165615</td>\n",
       "      <td>0.311255</td>\n",
       "      <td>-0.772552</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>0.683057</td>\n",
       "      <td>0.370284</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>0.535732</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.078033</td>\n",
       "      <td>-0.456348</td>\n",
       "      <td>-0.741198</td>\n",
       "      <td>-1.022429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.419418</td>\n",
       "      <td>0.378796</td>\n",
       "      <td>0.152052</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>0.716075</td>\n",
       "      <td>0.466021</td>\n",
       "      <td>0.940403</td>\n",
       "      <td>0.807166</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263861</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.679779</td>\n",
       "      <td>-0.552108</td>\n",
       "      <td>-0.774168</td>\n",
       "      <td>1.349270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows × 292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       0.419418    -0.020358 -0.103719     0.646183    -0.507284   1.046258   \n",
       "1      -1.120845     0.619103  0.146544    -0.063185     2.188279   0.154764   \n",
       "2       0.419418     0.118440  0.457629     0.646183    -0.507284   0.980221   \n",
       "3       0.638691    -0.266348  0.136301     0.646183    -0.507284  -1.859351   \n",
       "4       0.419418     0.769612  0.922662     1.355551    -0.507284   0.947203   \n",
       "...          ...          ...       ...          ...          ...        ...   \n",
       "1454    1.821276    -3.450727 -2.993401    -1.481920     1.289758  -0.043346   \n",
       "1455    1.821276    -3.450727 -3.036401    -1.481920    -0.507284  -0.043346   \n",
       "1456   -1.120845     2.764091  1.586172    -0.772552     1.289758  -0.373528   \n",
       "1457    0.915540    -0.165615  0.311255    -0.772552    -0.507284   0.683057   \n",
       "1458    0.419418     0.378796  0.152052     0.646183    -0.507284   0.716075   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  \\\n",
       "0         0.896833    1.219420    0.783352   -0.362698  ...   \n",
       "1        -0.395604   -0.801770    0.892570   -0.362698  ...   \n",
       "2         0.848965    1.146941    0.658276   -0.362698  ...   \n",
       "3        -0.682812   -0.801770    0.387039   -0.362698  ...   \n",
       "4         0.753229    1.440386    0.758231   -0.362698  ...   \n",
       "...            ...         ...         ...         ...  ...   \n",
       "1454     -0.682812   -0.801770   -1.418112   -0.362698  ...   \n",
       "1455     -0.682812   -0.801770    0.438541   -0.362698  ...   \n",
       "1456      0.561757   -0.801770    0.967785   -0.362698  ...   \n",
       "1457      0.370284   -0.801770    0.535732   -0.362698  ...   \n",
       "1458      0.466021    0.940403    0.807166   -0.362698  ...   \n",
       "\n",
       "      SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                 -0.263861              -0.064249              -0.09105   \n",
       "1                 -0.263861              -0.064249              -0.09105   \n",
       "2                 -0.263861              -0.064249              -0.09105   \n",
       "3                  3.789876              -0.064249              -0.09105   \n",
       "4                 -0.263861              -0.064249              -0.09105   \n",
       "...                     ...                    ...                   ...   \n",
       "1454              -0.263861              -0.064249              -0.09105   \n",
       "1455               3.789876              -0.064249              -0.09105   \n",
       "1456               3.789876              -0.064249              -0.09105   \n",
       "1457              -0.263861              -0.064249              -0.09105   \n",
       "1458              -0.263861              -0.064249              -0.09105   \n",
       "\n",
       "      SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \\\n",
       "0                -0.126535              0.463937              -0.302693   \n",
       "1                -0.126535              0.463937              -0.302693   \n",
       "2                -0.126535              0.463937              -0.302693   \n",
       "3                -0.126535             -2.155466              -0.302693   \n",
       "4                -0.126535              0.463937              -0.302693   \n",
       "...                    ...                   ...                    ...   \n",
       "1454             -0.126535              0.463937              -0.302693   \n",
       "1455             -0.126535             -2.155466              -0.302693   \n",
       "1456             -0.126535             -2.155466              -0.302693   \n",
       "1457             -0.126535              0.463937              -0.302693   \n",
       "1458             -0.126535              0.463937              -0.302693   \n",
       "\n",
       "      GarageYrBltn  YearRemodAddn  YearBuiltn        SF  \n",
       "0        -1.003156      -0.887271   -1.037932  1.198255  \n",
       "1         0.047817       0.357618   -0.180699 -0.572342  \n",
       "2        -0.922312      -0.839391   -0.971991  1.247255  \n",
       "3        -0.881890       0.597020    1.797529  0.681079  \n",
       "4        -0.881890      -0.743630   -0.939021  1.451561  \n",
       "...            ...            ...         ...       ...  \n",
       "1454     -0.078033       0.597020   -0.015847  0.518925  \n",
       "1455      0.249927       0.597020   -0.015847  0.518925  \n",
       "1456      0.654148      -0.647869    0.313858 -0.837880  \n",
       "1457     -0.078033      -0.456348   -0.741198 -1.022429  \n",
       "1458     -0.679779      -0.552108   -0.774168  1.349270  \n",
       "\n",
       "[2919 rows x 292 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = all_data.iloc[:1460,:]\n",
    "df_test = all_data.iloc[1460:,:]\n",
    "final = pd.concat([df_train,y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>GarageYrBltn</th>\n",
       "      <th>YearRemodAddn</th>\n",
       "      <th>YearBuiltn</th>\n",
       "      <th>SF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.419418</td>\n",
       "      <td>-0.020358</td>\n",
       "      <td>-0.103719</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>1.046258</td>\n",
       "      <td>0.896833</td>\n",
       "      <td>1.219420</td>\n",
       "      <td>0.783352</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-1.003156</td>\n",
       "      <td>-0.887271</td>\n",
       "      <td>-1.037932</td>\n",
       "      <td>1.198255</td>\n",
       "      <td>12.247699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.120845</td>\n",
       "      <td>0.619103</td>\n",
       "      <td>0.146544</td>\n",
       "      <td>-0.063185</td>\n",
       "      <td>2.188279</td>\n",
       "      <td>0.154764</td>\n",
       "      <td>-0.395604</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>0.892570</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>0.047817</td>\n",
       "      <td>0.357618</td>\n",
       "      <td>-0.180699</td>\n",
       "      <td>-0.572342</td>\n",
       "      <td>12.109016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.419418</td>\n",
       "      <td>0.118440</td>\n",
       "      <td>0.457629</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>0.848965</td>\n",
       "      <td>1.146941</td>\n",
       "      <td>0.658276</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.922312</td>\n",
       "      <td>-0.839391</td>\n",
       "      <td>-0.971991</td>\n",
       "      <td>1.247255</td>\n",
       "      <td>12.317171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.638691</td>\n",
       "      <td>-0.266348</td>\n",
       "      <td>0.136301</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>-1.859351</td>\n",
       "      <td>-0.682812</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>0.387039</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>-2.155466</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.881890</td>\n",
       "      <td>0.597020</td>\n",
       "      <td>1.797529</td>\n",
       "      <td>0.681079</td>\n",
       "      <td>11.849405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.419418</td>\n",
       "      <td>0.769612</td>\n",
       "      <td>0.922662</td>\n",
       "      <td>1.355551</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>0.947203</td>\n",
       "      <td>0.753229</td>\n",
       "      <td>1.440386</td>\n",
       "      <td>0.758231</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.881890</td>\n",
       "      <td>-0.743630</td>\n",
       "      <td>-0.939021</td>\n",
       "      <td>1.451561</td>\n",
       "      <td>12.429220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.419418</td>\n",
       "      <td>-0.165615</td>\n",
       "      <td>-0.231508</td>\n",
       "      <td>-0.063185</td>\n",
       "      <td>-0.507284</td>\n",
       "      <td>0.914184</td>\n",
       "      <td>0.753229</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>-1.418112</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>-0.881890</td>\n",
       "      <td>-0.791510</td>\n",
       "      <td>-0.939021</td>\n",
       "      <td>1.190896</td>\n",
       "      <td>12.072547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>-1.120845</td>\n",
       "      <td>0.806133</td>\n",
       "      <td>0.767440</td>\n",
       "      <td>-0.063185</td>\n",
       "      <td>0.391237</td>\n",
       "      <td>0.220801</td>\n",
       "      <td>0.178812</td>\n",
       "      <td>1.029776</td>\n",
       "      <td>0.821022</td>\n",
       "      <td>2.352645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>0.088239</td>\n",
       "      <td>-0.073305</td>\n",
       "      <td>-0.147729</td>\n",
       "      <td>-0.282342</td>\n",
       "      <td>12.254868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.638691</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.029092</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>3.086800</td>\n",
       "      <td>-1.000876</td>\n",
       "      <td>1.040437</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>0.467737</td>\n",
       "      <td>-0.362698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>1.583855</td>\n",
       "      <td>-0.935151</td>\n",
       "      <td>1.072179</td>\n",
       "      <td>1.255815</td>\n",
       "      <td>12.493133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>-1.120845</td>\n",
       "      <td>0.118440</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>-0.772552</td>\n",
       "      <td>0.391237</td>\n",
       "      <td>-0.703711</td>\n",
       "      <td>0.561757</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>-0.105486</td>\n",
       "      <td>3.330965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>1.220056</td>\n",
       "      <td>-0.456348</td>\n",
       "      <td>0.775444</td>\n",
       "      <td>-0.930488</td>\n",
       "      <td>11.864469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>-1.120845</td>\n",
       "      <td>0.420154</td>\n",
       "      <td>0.214215</td>\n",
       "      <td>-0.772552</td>\n",
       "      <td>0.391237</td>\n",
       "      <td>-0.208437</td>\n",
       "      <td>-0.922153</td>\n",
       "      <td>-0.801770</td>\n",
       "      <td>0.837575</td>\n",
       "      <td>2.657973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.09105</td>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>-0.302693</td>\n",
       "      <td>0.532882</td>\n",
       "      <td>0.932182</td>\n",
       "      <td>0.214946</td>\n",
       "      <td>-0.575817</td>\n",
       "      <td>11.901590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 293 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       0.419418    -0.020358 -0.103719     0.646183    -0.507284   1.046258   \n",
       "1      -1.120845     0.619103  0.146544    -0.063185     2.188279   0.154764   \n",
       "2       0.419418     0.118440  0.457629     0.646183    -0.507284   0.980221   \n",
       "3       0.638691    -0.266348  0.136301     0.646183    -0.507284  -1.859351   \n",
       "4       0.419418     0.769612  0.922662     1.355551    -0.507284   0.947203   \n",
       "...          ...          ...       ...          ...          ...        ...   \n",
       "1455    0.419418    -0.165615 -0.231508    -0.063185    -0.507284   0.914184   \n",
       "1456   -1.120845     0.806133  0.767440    -0.063185     0.391237   0.220801   \n",
       "1457    0.638691     0.026597  0.029092     0.646183     3.086800  -1.000876   \n",
       "1458   -1.120845     0.118440  0.170303    -0.772552     0.391237  -0.703711   \n",
       "1459   -1.120845     0.420154  0.214215    -0.772552     0.391237  -0.208437   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  \\\n",
       "0         0.896833    1.219420    0.783352   -0.362698  ...   \n",
       "1        -0.395604   -0.801770    0.892570   -0.362698  ...   \n",
       "2         0.848965    1.146941    0.658276   -0.362698  ...   \n",
       "3        -0.682812   -0.801770    0.387039   -0.362698  ...   \n",
       "4         0.753229    1.440386    0.758231   -0.362698  ...   \n",
       "...            ...         ...         ...         ...  ...   \n",
       "1455      0.753229   -0.801770   -1.418112   -0.362698  ...   \n",
       "1456      0.178812    1.029776    0.821022    2.352645  ...   \n",
       "1457      1.040437   -0.801770    0.467737   -0.362698  ...   \n",
       "1458      0.561757   -0.801770   -0.105486    3.330965  ...   \n",
       "1459     -0.922153   -0.801770    0.837575    2.657973  ...   \n",
       "\n",
       "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                 -0.064249              -0.09105             -0.126535   \n",
       "1                 -0.064249              -0.09105             -0.126535   \n",
       "2                 -0.064249              -0.09105             -0.126535   \n",
       "3                 -0.064249              -0.09105             -0.126535   \n",
       "4                 -0.064249              -0.09105             -0.126535   \n",
       "...                     ...                   ...                   ...   \n",
       "1455              -0.064249              -0.09105             -0.126535   \n",
       "1456              -0.064249              -0.09105             -0.126535   \n",
       "1457              -0.064249              -0.09105             -0.126535   \n",
       "1458              -0.064249              -0.09105             -0.126535   \n",
       "1459              -0.064249              -0.09105             -0.126535   \n",
       "\n",
       "      SaleCondition_Normal  SaleCondition_Partial  GarageYrBltn  \\\n",
       "0                 0.463937              -0.302693     -1.003156   \n",
       "1                 0.463937              -0.302693      0.047817   \n",
       "2                 0.463937              -0.302693     -0.922312   \n",
       "3                -2.155466              -0.302693     -0.881890   \n",
       "4                 0.463937              -0.302693     -0.881890   \n",
       "...                    ...                    ...           ...   \n",
       "1455              0.463937              -0.302693     -0.881890   \n",
       "1456              0.463937              -0.302693      0.088239   \n",
       "1457              0.463937              -0.302693      1.583855   \n",
       "1458              0.463937              -0.302693      1.220056   \n",
       "1459              0.463937              -0.302693      0.532882   \n",
       "\n",
       "      YearRemodAddn  YearBuiltn        SF  SalePrice  \n",
       "0         -0.887271   -1.037932  1.198255  12.247699  \n",
       "1          0.357618   -0.180699 -0.572342  12.109016  \n",
       "2         -0.839391   -0.971991  1.247255  12.317171  \n",
       "3          0.597020    1.797529  0.681079  11.849405  \n",
       "4         -0.743630   -0.939021  1.451561  12.429220  \n",
       "...             ...         ...       ...        ...  \n",
       "1455      -0.791510   -0.939021  1.190896  12.072547  \n",
       "1456      -0.073305   -0.147729 -0.282342  12.254868  \n",
       "1457      -0.935151    1.072179  1.255815  12.493133  \n",
       "1458      -0.456348    0.775444 -0.930488  11.864469  \n",
       "1459       0.932182    0.214946 -0.575817  11.901590  \n",
       "\n",
       "[1460 rows x 293 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge, HuberRegressor, Ridge, OrthogonalMatchingPursuit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = GradientBoostingRegressor()\n",
    "baseline_model.fit(df_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_params = {\n",
    "    'n_iter': 304,\n",
    "    'tol': 0.16864712769300896,\n",
    "    'alpha_1': 5.589616542154059e-07,\n",
    "    'alpha_2': 9.799343618469923,\n",
    "    'lambda_1': 1.7735725582463822,\n",
    "    'lambda_2': 3.616928181181732e-06\n",
    "}\n",
    "\n",
    "\n",
    "ridge_params = {\n",
    "    'alpha': 10\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'gbr':GradientBoostingRegressor(),\n",
    "          'br':BayesianRidge(**br_params),\n",
    "          'ridge':Ridge(**ridge_params),\n",
    "          'catboost':CatBoostRegressor(loss_function='RMSE',n_estimators=15000, verbose = 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(df_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for name, model in models.items():\n",
    "    result = np.exp(np.sqrt(-cross_val_score(model, df_train, y, scoring='neg_mean_squared_error', cv=kf)))\n",
    "    results[name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, result in results.items():\n",
    "    print(\"----------\\n\" + name)\n",
    "    print(np.mean(result))\n",
    "    print(np.std(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (\n",
    "    0.0 * np.exp(models['gbr'].predict(df_test)) +\n",
    "    0.0 * np.exp(models['br'].predict(df_test)) +\n",
    "    0.0 * np.exp(models['ridge'].predict(df_test))+\n",
    "    1 * np.exp(models['catboost'].predict(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":y_pred})\n",
    "# solution.to_csv(\"ridge_sol.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [100]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msolution\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'solution' is not defined"
     ]
    }
   ],
   "source": [
    "solution.to_csv('submission.csv',index=False) #Score: 0.12299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [101]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msolution\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'solution' is not defined"
     ]
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ensemble model with some feature engineering gives us better result at public leaderboard 0.124, than by using just xgboost 0.132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
