{"cells":[{"cell_type":"markdown","metadata":{"id":"5Yi5w2oLHzNm"},"source":["**Unstructured Data Analytics: Group Assignment #2**\n","\n","# Group Members:\n","1. Rithu Anand Krishnan\n","2. Manvi Mahajan\n","3. Paul Wen (Yilin Wen)\n","4. Alex Yu\n","5. Judy Chen (Yu-Ting Chen)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"z1NDz1TjrXFv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b34a695-14c3-441c-b658-138e328a9267","executionInfo":{"status":"ok","timestamp":1670125345014,"user_tz":360,"elapsed":9673,"user":{"displayName":"Rithu A","userId":"09796671281867964761"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting snscrape\n","  Downloading snscrape-0.4.3.20220106-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.6.3)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from snscrape) (2.23.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.9.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from snscrape) (2022.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from snscrape) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2022.9.24)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.7.1)\n","Installing collected packages: snscrape\n","Successfully installed snscrape-0.4.3.20220106\n"]}],"source":["## Imports\n","!pip install snscrape\n","import snscrape.modules.twitter as sntwitter\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R9tXNsQwymxM"},"outputs":[],"source":["#Creating an empty list to append tweet data to\n","usr_twt_list = []\n","search_termsUT = ['marijuana arkansas','weed arkansas']\n","#Using TwitterSearchScraper to scrape data and append tweets to list\n","for j in search_termsUT:\n","  for i,tweet in enumerate(sntwitter.TwitterSearchScraper(j).get_items()): #declare a username \n","      if i>10000: #number of tweets you want to scrape\n","          break\n","      usr_twt_list.append([tweet.user.username, tweet.user.location, tweet.content]) #declare the attributes to be returned\n","      i+=1\n","\n","#Creating a dataframe from the tweets list above \n","df = pd.DataFrame(usr_twt_list, columns=['username', 'location', 'text'])\n","filename = 'ASLegalize.csv'\n","df.to_csv(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txGUXc6VymxO"},"outputs":[],"source":["df.shape"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"275c13896ba8c4530b3b5edd72df101d8643eb4aa3956a7fd1b30cb9fb9264ee"}}},"nbformat":4,"nbformat_minor":0}