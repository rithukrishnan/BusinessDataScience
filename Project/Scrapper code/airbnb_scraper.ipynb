{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9ER-eKFfCjO",
    "outputId": "f8ad1dc5-cbcb-4cde-81bc-ca5fd8554c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.7.2-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3[socks]~=1.26 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from selenium) (1.26.11)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from selenium) (2022.6.15.1)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sortedcontainers, PySocks, outcome, h11, exceptiongroup, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed PySocks-1.7.1 async-generator-1.10 exceptiongroup-1.0.4 h11-0.14.0 outcome-1.2.0 selenium-4.7.2 sortedcontainers-2.4.0 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "zsh:1: command not found: apt-get\n",
      "The operation couldn’t be completed. Unable to locate a Java Runtime that supports apt.\n",
      "Please visit http://www.java.com for information on installing Java.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/xs_xkf814zx898m2wdld0hw40000gn/T/ipykernel_50337/1116997257.py:10: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!apt-get update \n",
    "!apt install chromium-chromedriver\n",
    "\n",
    "from selenium import webdriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jLadO2ZdefIz"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "import multiprocessing\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "id": "h4WAOXfoexqY",
    "outputId": "f46e12d6-7d17-4a58-e770-f241d9569749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.7.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from selenium) (2022.6.15.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: outcome in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mEA9aFVwefI1"
   },
   "outputs": [],
   "source": [
    "PATH=\"C:\\Program Files (x86)\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Xc5KjvjIefI2",
    "outputId": "a1803e86-b56e-4c30-e185-e9be515a68b7"
   },
   "outputs": [],
   "source": [
    "#driver=webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HdgcggjpefI2"
   },
   "outputs": [],
   "source": [
    "AIRBNB_LINK = 'https://www.airbnb.com/s/Fort-Myers--Florida/homes?tab_id=home_tab&refinement_paths%5B%5D=%2Fhomes&flexible_trip_lengths%5B%5D=one_week&price_filter_input_type=0&price_filter_num_nights=5&source=structured_search_input_header&search_type=search_query&query=Matagorda%2C%20Texas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3rsrQzzbefI3"
   },
   "outputs": [],
   "source": [
    "RULES_SEARCH_PAGE = {\n",
    "#     'url': {'tag': 'a', 'get': 'href'},\n",
    "#     'name': {'tag': 'div', 'class': '_hxt6u1e', 'get': 'aria-label'},\n",
    "#     'name_alt': {'tag': 'a', 'get': 'aria-label'},\n",
    "#     'header': {'tag': 'div', 'class': '_b14dlit'},\n",
    "#     'rooms': {'tag': 'div', 'class': '_kqh46o'},\n",
    "#     'facilities': {'tag': 'div', 'class': '_kqh46o', 'order': 1},\n",
    "#     'badge': {'tag': 'div', 'class': '_17bkx6k'},\n",
    "#     'rating_n_reviews': {'tag': 'span', 'class': '_18khxk1'},\n",
    "#     'price': {'tag': 'span', 'class': '_1p7iugi'},\n",
    "#     'price_alt': {'tag': 'span', 'class': '_olc9rf0'},\n",
    "#     'superhost': {'tag': 'div', 'class': '_ufoy4t'},\n",
    "      \n",
    "      'url':{'tag':'a', 'class':'rfexzly dir dir-ltr','get':'href'},\n",
    "      'description':{'tag':'span','class':'t6mzqp7 dir dir-ltr'},\n",
    "      'name':{'tag':'div','class':'t1jojoys dir dir-ltr'},\n",
    "      'superhost': {'tag': 'div', 'class': 't1mwk1n0 dir dir-ltr'},\n",
    "      'price per night': {'tag': 'span', 'class': '_tyxjp1'},\n",
    "      'actual price': {'tag': 'span', 'class': '_1ks8cgb'},\n",
    "      'beds': {'tag': 'span', 'class': 'dir dir-ltr'},\n",
    "      'rating':{'tag':'span'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CIoIfiVAefI3"
   },
   "outputs": [],
   "source": [
    "RULES_DETAIL_PAGE = {\n",
    "    'location': {'tag': 'span', 'class': '_9xiloll'},\n",
    "    'unit rental details': {'tag': 'div', 'class': '_tqmy57'},\n",
    "    #'number of guests': {'tag': 'li', 'class': 'l7n4lsf dir dir-ltr'},\n",
    "    'number of guests': {'tag': 'li', 'class': 'l7n4lsf dir dir-ltr', 'order': -1},\n",
    "    'more description': {'tag': 'span', 'class': 'll4r2nl dir dir-ltr'},\n",
    "    #'amenities': {'tag': 'div', 'class': 'iikjzje i10xc1ab dir dir-ltr'},#order\n",
    "    #'house rules': {'tag': 'div', 'class': 'sahkfss dir dir-ltr'}, #order\n",
    "   'amenities1': {'tag': 'div', 'class': 'iikjzje i10xc1ab dir dir-ltr', 'order': -1},#order\n",
    "    #'house rules2': {'tag': 'div', 'class': 'sahkfss dir dir-ltr', 'order': -1}, #order\n",
    "    #'image_urls': {'tag': 'source'}\n",
    "    'rating':{'tag': 'span', 'class':'_17p6nbba'},\n",
    "    \n",
    "    \n",
    "#     'specialties_1': {'tag': 'div', 'class': 't1bchdij', 'order': -1},\n",
    "#     'specialties_2': {'tag': 'div', 'class': '_1qsawv5', 'order': -1},\n",
    "\n",
    "#     'price_per_night': {'tag': 'div', 'class': '_ymq6as'},\n",
    "    \n",
    "#     'refundables': {'tag': 'div', 'class': '_cexc0g', 'order': -1},\n",
    "        \n",
    "#     'prices_1': {'tag': 'li', 'class': '_ryvszj', 'order': -1},\n",
    "#     'prices_2': {'tag': 'li', 'class': '_adhikmk', 'order': -1},\n",
    "    \n",
    "#     'listing_ratings': {'tag': 'span', 'class': '_4oybiu', 'order': -1},\n",
    "    \n",
    "#     'host_joined': {'tag': 'div', 'class': '_1fg5h8r', 'order': 1},\n",
    "#     'host_feats': {'tag': 'span', 'class': '_pog3hg', 'order': -1},\n",
    "    \n",
    "#     'lang_responses': {'tag': 'li', 'class': '_1q2lt74', 'order': -1},\n",
    "#     'house_rules': {'tag': 'div', 'class': '_u827kd', 'order': -1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dNkR3rpKefI4"
   },
   "outputs": [],
   "source": [
    "def extract_image_urls(soup):\n",
    "    print(\"inside image function\")\n",
    "    #parsed_html = BeautifulSoup(soup)\n",
    "    new_soup=soup.find_all('li',{'class':'_145ocfuw'})\n",
    "    #print(new_soup)\n",
    "    list1=[]\n",
    "    for i in new_soup:\n",
    "        parsed_html = BeautifulSoup(i)\n",
    "        for source in parsed_html.body.find_all('source'):\n",
    "            print('source image',source['srcset'])\n",
    "            list1.append(source['srcset'])  \n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PnLu8vk4efI4"
   },
   "outputs": [],
   "source": [
    "def extract_listings(page_url, attempts=10):\n",
    "    \"\"\"Extracts all listings from a given page\"\"\"\n",
    "    #print(\"inside listings\")\n",
    "    listings_max = 0\n",
    "    listings_out = [BeautifulSoup('', features='html.parser')]\n",
    "    for idx in range(attempts):\n",
    "        try:\n",
    "            answer = requests.get(page_url, timeout=5)\n",
    "            content = answer.content\n",
    "            soup = BeautifulSoup(content, features='html.parser')\n",
    "            listings = soup.findAll(\"div\", {\"class\": \"c4mnd7m dir dir-ltr\"})\n",
    "        except:\n",
    "            # if no response - return a list with an empty soup\n",
    "            listings = [BeautifulSoup('', features='html.parser')]\n",
    "\n",
    "        if len(listings) == 20:\n",
    "            listings_out = listings\n",
    "            break\n",
    "\n",
    "        if len(listings) >= listings_max:\n",
    "            listings_max = len(listings)\n",
    "            listings_out = listings\n",
    "    #print(\"cameout listings\")\n",
    "    return listings_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "srIKey8sefI4"
   },
   "outputs": [],
   "source": [
    "def extract_element_data(soup, params):\n",
    "    \"\"\"Extracts data from a specified HTML element\"\"\"\n",
    "    #print(\"inside element data\")\n",
    "    # 1. Find the right tag\n",
    "    if 'class' in params:\n",
    "        \n",
    "        elements_found = soup.find_all(params['tag'], params['class'])\n",
    "    else:\n",
    "        elements_found = soup.find_all(params['tag'])\n",
    "        \n",
    "    # 2. Extract text from these tags\n",
    "    if 'get' in params:\n",
    "        element_texts = [el.get(params['get']) for el in elements_found]\n",
    "        #print(\"inside if\",element_texts)\n",
    "    else:\n",
    "        element_texts = [el.get_text() for el in elements_found]\n",
    "        #print(\"inside else\",element_texts)\n",
    "        \n",
    "    # 3. Select a particular text or concatenate all of them\n",
    "    tag_order = params.get('order', 0)\n",
    "    if tag_order == -1:\n",
    "        output = '**__**'.join(element_texts)\n",
    "    else:\n",
    "        output = element_texts[tag_order]\n",
    "    #print(\"output\",output)\n",
    "    #print(\"came out element data\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "K3pMbfnLefI5"
   },
   "outputs": [],
   "source": [
    "def extract_listing_features(soup, rules):\n",
    "    \"\"\"Extracts all features from the listing\"\"\"\n",
    "    features_dict = {}\n",
    "    for feature in rules:\n",
    "        try:\n",
    "            features_dict[feature] = extract_element_data(soup, rules[feature])\n",
    "            #print(feature, features_dict[feature])\n",
    "        except:\n",
    "            features_dict[feature] = 'empty'\n",
    "    #print(features_dict)\n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PqBeOKVOefI5"
   },
   "outputs": [],
   "source": [
    "def extract_house_rules_data(soup, params):\n",
    "    house_rules3 = soup.find_all('div', 'sahkfss dir dir-ltr')\n",
    "    #print(\"house_rules3\",house_rules3)\n",
    "    #print(\"inside amenities\")\n",
    "    House_rules_list = []\n",
    "    house_dict={}\n",
    "    for Hrule in house_rules3:\n",
    "        #print(\"Hrule\",Hrule)\n",
    "        tags = Hrule.find_all('div')\n",
    "        for i in tags:\n",
    "            House_rules_list.append(i.get_text())\n",
    "        \n",
    "    house_dict['all_rules'] = House_rules_list\n",
    "    #print(\"cameout of amenities\")  \n",
    "    #print(\"all house rules\",House_rules_list)\n",
    "    return House_rules_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Fw68u-ngefI5"
   },
   "outputs": [],
   "source": [
    "def extract_soup_js(listing_url, waiting_time=[20, 1]):\n",
    "    \"\"\"Extracts HTML from JS pages: open, wait, click, wait, extract\"\"\"\n",
    "    #print(\"inside soup_js function\")\n",
    "    # options = Options()\n",
    "    # options.add_argument('--headless')\n",
    "    # options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "    # #driver = webdriver.Chrome(PATH,options=options)\n",
    "    # driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"start-maximized\")\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver=webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    \n",
    "\n",
    "    # if the URL is not valid - return an empty soup\n",
    "    try:\n",
    "        #print(\"inside timeout\")\n",
    "        driver.get(listing_url)\n",
    "    except:\n",
    "        print(f\"Wrong URL: {listing_url}\")\n",
    "        return BeautifulSoup('', features='html.parser')\n",
    "    \n",
    "    # waiting for an element on the bottom of the page to load (\"More places to stay\")\n",
    "    try:\n",
    "        myElem = WebDriverWait(driver, waiting_time[0]).until(EC.presence_of_element_located((By.CLASS_NAME, 'i1o80ipj dir dir-ltr')))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # click cookie policy\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"/html/body/div[6]/div/div/div[1]/section/footer/div[2]/button\").click()\n",
    "    except:\n",
    "        pass\n",
    "    # alternative click cookie policy\n",
    "    try:\n",
    "        element = driver.find_element_by_xpath(\"//*[@data-testid='main-cookies-banner-container']\")\n",
    "        element.find_element_by_xpath(\"//button[@data-testid='accept-btn']\").click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # looking for price details\n",
    "    price_dropdown = 0\n",
    "    try:\n",
    "        element = driver.find_element_by_class_name('_gby1jkw')\n",
    "        price_dropdown = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # if the element is present - click on it\n",
    "    if price_dropdown == 1:\n",
    "        for i in range(10): # 10 attempts to scroll to the price button\n",
    "            try:\n",
    "                actions = ActionChains(driver)\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", element);\n",
    "                actions.move_to_element_with_offset(element, 5, 5)\n",
    "                actions.click().perform()\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    # looking for amenities\n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    try:\n",
    "        #print(\"amenities soup\")\n",
    "        driver.find_element_by_class_name('b65jmrv bgpdp7p v7aged4 dir dir-ltr').click()\n",
    "    except:\n",
    "        pass # amenities button not found\n",
    "\n",
    "    time.sleep(waiting_time[1])\n",
    "\n",
    "    detail_page = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "    #print(\"outside soup_js function\")\n",
    "\n",
    "    return BeautifulSoup(detail_page, features='html.parser')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9pSjOzF9efI6"
   },
   "outputs": [],
   "source": [
    "def scrape_detail_page(base_features):\n",
    "    \"\"\"Scrapes the detail page and merges the result with basic features\"\"\"\n",
    "    \n",
    "    detailed_url = 'https://www.airbnb.com' + base_features['url']\n",
    "    #print(\"detailed url\",detailed_url)\n",
    "    soup_detail = extract_soup_js(detailed_url)\n",
    "    #print(soup_detail)\n",
    "    features_detailed = extract_listing_features(soup_detail, RULES_DETAIL_PAGE)\n",
    "    features_amenities = extract_amenities_main(detailed_url)\n",
    "    features_rental_data=extract_rental_data(detailed_url)\n",
    "    features_host_about=extract_host_about(detailed_url)\n",
    "    features_image_urls=extract_image_urls(detailed_url)\n",
    "    #extract_additional_features(detailed_url)\n",
    "    #features_images = extract_image_urls(soup_detail)\n",
    "    #features_amenities, features_image_urls, features_rental_data, features_host_about = extract_selenium_features(detailed_url)\n",
    "    features_detailed['rental_data'] = features_rental_data\n",
    "    features_detailed['all_amenities'] = features_amenities\n",
    "    features_detailed['image_urls'] = features_image_urls\n",
    "    features_detailed['host_about'] = features_host_about\n",
    "    \n",
    "    #features_detailed['all_images'] = features_images\n",
    "    features_all = {**base_features, **features_detailed}\n",
    "    #print(features_all)\n",
    "    return features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MJhdLZ-mefI6"
   },
   "outputs": [],
   "source": [
    "def extract_selenium_features(url):\n",
    "    \"\"\"\n",
    "    return image_urls, all_amenities, rental_data\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions() \n",
    "    # options.add_argument(\"start-maximized\")\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option('useAutomationExtension', False)\n",
    "    #driver = webdriver.Chrome(PATH, options=options)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"start-maximized\")\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver=webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    driver.get(url)\n",
    "    image_urls = []\n",
    "    amenities = []\n",
    "    try:    \n",
    "        WebDriverWait(driver, 40).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[5]/div/div/div[1]/div/div[1]/div/div/div/div/div[1]/main/div/div[1]/div[1]/div[2]/div/div/div/div/div/div/div/div[2]/button\"))).click()\n",
    "        elements = WebDriverWait(driver, 80).until(EC.visibility_of_all_elements_located((By.XPATH, \"//img[contains(@class,'_6tbg2q')]\")))\n",
    "        for el in elements:\n",
    "            image_urls.append(el.get_attribute('data-original-uri'))\n",
    "        driver.get(url)\n",
    "    except Exception as e:\n",
    "        print(\"images didnot come:\", url)\n",
    "        driver.get(url)\n",
    "        \n",
    "    try:\n",
    "        WebDriverWait(driver, 40).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[5]/div/div/div[1]/div/div[1]/div/div/div/div/div[1]/main/div/div[1]/div[3]/div/div[1]/div/div[6]/div/div[2]/section/div[4]/button\"))).click()\n",
    "        for el in WebDriverWait(driver, 80).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, \"div._11jhslp\"))):\n",
    "            amenities.append(el.text.strip())\n",
    "        driver.get(url)\n",
    "    except Exception as e:\n",
    "        print(\"amentities didnot come:\", url)\n",
    "        driver.get(url)\n",
    "        \n",
    "    try:\n",
    "        rental_data = ''\n",
    "        data = WebDriverWait(driver, 40).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, \"div._cv5qq4\")))\n",
    "        rental_data = data[0].text.strip()\n",
    "        driver.get(url)\n",
    "    except Exception as e:\n",
    "        print(\"rental data didnot come:\", url)\n",
    "        driver.get(url)\n",
    "    try:\n",
    "        data = WebDriverWait(driver, 30).until(EC.visibility_of_all_elements_located((By.XPATH, \"//div[contains(@data-plugin-in-point-id,'HOST_PROFILE_DEFAULT')]\")))\n",
    "        host_about = data[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "#         try:\n",
    "#             if WebDriverWait(driver, 100).until(EC.visibility_of_all_elements_located((By.XPATH, \"//div[contains(@data-plugin-in-point-id,'HOST_PROFILE_DEFAULT')]\"))):\n",
    "#                 host_about = \"host data is there\"\n",
    "#         except:    \n",
    "        host_about = \"host data is not there\"\n",
    "        \n",
    "    return amenities, image_urls, rental_data, host_about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SMptHjrgefI6"
   },
   "outputs": [],
   "source": [
    "def extract_host_about(url):\n",
    "     #print(\"inside amenities\")\n",
    "    # options = webdriver.ChromeOptions() \n",
    "    # options.add_argument(\"start-maximized\")\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option('useAutomationExtension', False)\n",
    "    # driver = webdriver.Chrome(PATH)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"start-maximized\")\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver=webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    host_about=''\n",
    "    try:\n",
    "        data = WebDriverWait(driver, 30).until(EC.visibility_of_all_elements_located((By.XPATH, \"//div[contains(@data-plugin-in-point-id,'HOST_PROFILE_DEFAULT')]\")))\n",
    "        host_about = data[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        host_about = \"host data is not there\"\n",
    "    return(host_about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NzY6yCf4efI7"
   },
   "outputs": [],
   "source": [
    "def extract_rental_data(url):\n",
    "     #print(\"inside amenities\")\n",
    "    # options = webdriver.ChromeOptions() \n",
    "    # options.add_argument(\"start-maximized\")\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option('useAutomationExtension', False)\n",
    "    # driver = webdriver.Chrome(PATH)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"start-maximized\")\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver=webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    driver.get(url)\n",
    "    rental_data=''\n",
    "    try:\n",
    "        data=WebDriverWait(driver, 40).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, \"div._cv5qq4\")))\n",
    "        rental_data=data[0].text.strip()\n",
    "    except:\n",
    "        print(\"rental_data not available\")\n",
    "    return(rental_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HUMbuiVyefI7"
   },
   "outputs": [],
   "source": [
    "def extract_image_urls(url):\n",
    "    # options = webdriver.ChromeOptions() \n",
    "    # options.add_argument(\"start-maximized\")\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option('useAutomationExtension', False)\n",
    "    # driver = webdriver.Chrome(PATH)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"start-maximized\")\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver=webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    driver.get(url)\n",
    "    image_urls = []\n",
    "    try:    \n",
    "        WebDriverWait(driver, 40).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[5]/div/div/div[1]/div/div[1]/div/div/div/div/div[1]/main/div/div[1]/div[1]/div[2]/div/div/div/div/div/div/div/div[2]/button\"))).click()\n",
    "        elements = WebDriverWait(driver, 80).until(EC.visibility_of_all_elements_located((By.XPATH, \"//img[contains(@class,'_6tbg2q')]\")))\n",
    "        for el in elements:\n",
    "            image_urls.append(el.get_attribute('data-original-uri'))\n",
    "    except Exception as e:\n",
    "        print(\"images didnot come:\", url)\n",
    "    return image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zcsPQKlZefI7"
   },
   "outputs": [],
   "source": [
    "def extract_amenities(soup):\n",
    "    amenities = soup.find_all('div', {'class': '_aujnou'})\n",
    "    #print(\"inside amenities\")\n",
    "    amenities_dict = {}\n",
    "    for amenity in amenities:\n",
    "        header = amenity.find('div', {'class': '_1crk6cd'}).get_text()\n",
    "        values = amenity.find_all('div', {'class': '_1dotkqq'})\n",
    "        values = [v.find(text=True) for v in values]\n",
    "        \n",
    "        amenities_dict['amenity_' + header] = values\n",
    "    #print(\"cameout of amenities\")   \n",
    "    return json.dumps(amenities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Yi8EU22vefI7"
   },
   "outputs": [],
   "source": [
    "def extract_amenities_main(url):\n",
    "    #print(\"inside amenities\")\n",
    "    # options = webdriver.ChromeOptions() \n",
    "    # options.add_argument(\"start-maximized\")\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option('useAutomationExtension', False)\n",
    "    # driver = webdriver.Chrome(PATH, options=options)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"start-maximized\")\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver=webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    driver.get(url)\n",
    "    amenities = []\n",
    "    try:\n",
    "        #print(\"inside try\")\n",
    "        WebDriverWait(driver, 40).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[5]/div/div/div[1]/div/div[1]/div/div/div/div/div[1]/main/div/div[1]/div[3]/div/div[1]/div/div[6]/div/div[2]/section/div[4]/button\"))).click()\n",
    "        for el in WebDriverWait(driver, 70).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, \"div._11jhslp\"))):\n",
    "            amenities.append(el.text.strip())\n",
    "    except:\n",
    "        print(url)\n",
    "        #amenities.append()\n",
    "    return(amenities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1eu6d1zPefI8"
   },
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, link, out_file):\n",
    "        self.link = link\n",
    "        self.out_file = out_file\n",
    "\n",
    "    \n",
    "    def build_urls(self, listings_per_page=20, pages_per_location=15):\n",
    "        \"\"\"Builds links for all search pages for a given location\"\"\"\n",
    "        url_list = []\n",
    "        for i in range(pages_per_location):\n",
    "            offset = listings_per_page * i\n",
    "            url_pagination = self.link + f'&items_offset={offset}'\n",
    "            url_list.append(url_pagination)\n",
    "            self.url_list = url_list\n",
    "\n",
    "\n",
    "    def process_search_pages(self):\n",
    "        \"\"\"Extract features from all search pages\"\"\"\n",
    "        features_list = []\n",
    "        for page in self.url_list:\n",
    "            listings = extract_listings(page)\n",
    "            for listing in listings:\n",
    "                features = extract_listing_features(listing, RULES_SEARCH_PAGE)\n",
    "                features['sp_url'] = page\n",
    "                features_list.append(features)\n",
    "        \n",
    "        self.base_features_list = features_list\n",
    "\n",
    "        \n",
    "\n",
    "    def process_detail_pages(self):\n",
    "        print(\"in the details\")\n",
    "        \"\"\"Runs detail pages processing in parallel\"\"\"\n",
    "#         pool = multiprocessing.Pool()\n",
    "#         pool = multiprocessing.Pool(processes=4)\n",
    "#         result = pool.map(scrape_detail_page, self.base_features_list)\n",
    "#         pool.close()\n",
    "#         pool.join()\n",
    "        result=[]\n",
    "        #print(self.base_features_list)\n",
    "        for i in self.base_features_list:\n",
    "            result.append(scrape_detail_page(i))\n",
    "        self.all_features_list = result\n",
    "\n",
    "\n",
    "    def save(self, feature_set='all'):\n",
    "        if feature_set == 'basic':\n",
    "            pd.DataFrame(self.base_features_list).to_csv(self.out_file, index=False)\n",
    "        elif feature_set == 'all':\n",
    "            pd.DataFrame(self.all_features_list).to_csv(self.out_file, index=False)\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "    def parse(self):\n",
    "        self.build_urls()\n",
    "        self.process_search_pages()\n",
    "        self.process_detail_pages()\n",
    "        self.save('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFfEfnIkefI8",
    "outputId": "35998998-cb95-4375-9664-21202e3eef57",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the details\n",
      "https://www.airbnb.com/rooms/607174402441881460?adults=1&children=0&infants=0&pets=0&check_in=2022-12-04&check_out=2022-12-09&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/53252223?adults=1&children=0&infants=0&pets=0&check_in=2023-01-01&check_out=2023-01-06&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/16595711?adults=1&children=0&infants=0&pets=0&check_in=2022-12-04&check_out=2022-12-09&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/660340694276649651?adults=1&children=0&infants=0&pets=0&check_in=2023-03-04&check_out=2023-03-11&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/574798753832981813?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/734893291635050647?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/568413108027725492?adults=1&children=0&infants=0&pets=0&check_in=2022-12-12&check_out=2022-12-19&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/37173558?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/37173558?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/696253557106417585?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-10&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/613252574099353548?adults=1&children=0&infants=0&pets=0&check_in=2022-12-04&check_out=2022-12-09&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/50326475?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-10&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/605025294029051622?adults=1&children=0&infants=0&pets=0&check_in=2022-12-09&check_out=2022-12-15&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/660635034397024184?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/729055047200899544?adults=1&children=0&infants=0&pets=0&check_in=2022-12-17&check_out=2022-12-22&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/610760580693580269?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-10&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/53190853?adults=1&children=0&infants=0&pets=0&check_in=2022-12-10&check_out=2022-12-16&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/618164239894446570?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/31809361?adults=1&children=0&infants=0&pets=0&check_in=2022-12-04&check_out=2022-12-09&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/734893291635050647?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/548048895579261300?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-10&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/37885358?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/31809361?adults=1&children=0&infants=0&pets=0&check_in=2022-12-04&check_out=2022-12-09&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/548048895579261300?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-10&previous_page_section_name=1000\n",
      "images didnot come: https://www.airbnb.com/rooms/37832767?adults=1&children=0&infants=0&pets=0&check_in=2022-12-04&check_out=2022-12-09&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/53613439?adults=1&children=0&infants=0&pets=0&check_in=2022-12-12&check_out=2022-12-19&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/39655735?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/666615289277867073?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/53190853?adults=1&children=0&infants=0&pets=0&check_in=2022-12-10&check_out=2022-12-16&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/26912062?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/699352865915495309?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/39655735?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/757248657017051169?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "Message: \n",
      "\n",
      "https://www.airbnb.com/rooms/53036463?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-10&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/710578425780026587?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/757248657017051169?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "Message: \n",
      "\n",
      "https://www.airbnb.com/rooms/52123204?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/657775321520989005?adults=1&children=0&infants=0&pets=0&check_in=2022-12-08&check_out=2022-12-14&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/712226690079846336?adults=1&children=0&infants=0&pets=0&check_in=2022-12-09&check_out=2022-12-14&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/47116914?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "https://www.airbnb.com/rooms/44124234?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-10&previous_page_section_name=1000\n",
      "Message: \n",
      "\n",
      "https://www.airbnb.com/rooms/596417454885114435?adults=1&children=0&infants=0&pets=0&check_in=2023-01-09&check_out=2023-01-14&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/675566388013498860?adults=1&children=0&infants=0&pets=0&check_in=2023-02-01&check_out=2023-02-06&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/26911767?adults=1&children=0&infants=0&pets=0&check_in=2022-12-06&check_out=2022-12-11&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/660346647494457020?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-10&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/757248430306166691?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "Message: \n",
      "\n",
      "https://www.airbnb.com/rooms/45704062?adults=1&children=0&infants=0&pets=0&check_in=2022-12-04&check_out=2022-12-09&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/43256063?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-10&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/584084365672568307?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-09&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/666117293567254572?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/766922604650478162?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/691910807163279264?adults=1&children=0&infants=0&pets=0&check_in=2022-12-05&check_out=2022-12-11&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/29806590?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images didnot come: https://www.airbnb.com/rooms/29806590?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/26912035?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/53583944?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/715860780217957687?adults=1&children=0&infants=0&pets=0&check_in=2022-12-04&check_out=2022-12-09&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/739868670737607493?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/739849293009421366?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/38489555?adults=1&children=0&infants=0&pets=0&check_in=2022-12-03&check_out=2022-12-08&previous_page_section_name=1000\n",
      "https://www.airbnb.com/rooms/736841968934371105?adults=1&children=0&infants=0&pets=0&check_in=2022-12-04&check_out=2022-12-09&previous_page_section_name=1000\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: Unable to receive message from renderer\n  (failed to check if window was closed: timeout: Timed out receiving message from renderer: 600.000)\n  (Session info: headless chrome=108.0.5359.94)\nStacktrace:\n0   chromedriver                        0x0000000102a9ff38 chromedriver + 4910904\n1   chromedriver                        0x0000000102a1fa03 chromedriver + 4385283\n2   chromedriver                        0x0000000102664747 chromedriver + 472903\n3   chromedriver                        0x000000010264d427 chromedriver + 377895\n4   chromedriver                        0x000000010264d0a0 chromedriver + 376992\n5   chromedriver                        0x000000010264c2d6 chromedriver + 373462\n6   chromedriver                        0x000000010266da7d chromedriver + 510589\n7   chromedriver                        0x00000001026ea4da chromedriver + 1021146\n8   chromedriver                        0x00000001026ceee3 chromedriver + 909027\n9   chromedriver                        0x000000010269930c chromedriver + 688908\n10  chromedriver                        0x000000010269a88e chromedriver + 694414\n11  chromedriver                        0x0000000102a6d1de chromedriver + 4702686\n12  chromedriver                        0x0000000102a71b19 chromedriver + 4721433\n13  chromedriver                        0x0000000102a7928e chromedriver + 4752014\n14  chromedriver                        0x0000000102a7291a chromedriver + 4725018\n15  chromedriver                        0x0000000102a46b02 chromedriver + 4545282\n16  chromedriver                        0x0000000102a91888 chromedriver + 4851848\n17  chromedriver                        0x0000000102a91a05 chromedriver + 4852229\n18  chromedriver                        0x0000000102aa7e5f chromedriver + 4943455\n19  libsystem_pthread.dylib             0x00007ff81175e4f4 _pthread_start + 125\n20  libsystem_pthread.dylib             0x00007ff81175a00f thread_start + 15\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_urls()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_search_pages()\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_detail_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mParser.process_detail_pages\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#print(self.base_features_list)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_features_list:\n\u001b[0;32m---> 42\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(\u001b[43mscrape_detail_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_features_list \u001b[38;5;241m=\u001b[39m result\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mscrape_detail_page\u001b[0;34m(base_features)\u001b[0m\n\u001b[1;32m      9\u001b[0m features_amenities \u001b[38;5;241m=\u001b[39m extract_amenities_main(detailed_url)\n\u001b[1;32m     10\u001b[0m features_rental_data\u001b[38;5;241m=\u001b[39mextract_rental_data(detailed_url)\n\u001b[0;32m---> 11\u001b[0m features_host_about\u001b[38;5;241m=\u001b[39m\u001b[43mextract_host_about\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetailed_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m features_image_urls\u001b[38;5;241m=\u001b[39mextract_image_urls(detailed_url)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#extract_additional_features(detailed_url)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#features_images = extract_image_urls(soup_detail)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#features_amenities, features_image_urls, features_rental_data, features_host_about = extract_selenium_features(detailed_url)\u001b[39;00m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mextract_host_about\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     14\u001b[0m chrome_options\u001b[38;5;241m.\u001b[39madd_experimental_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124museAutomationExtension\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m driver\u001b[38;5;241m=\u001b[39mwebdriver\u001b[38;5;241m.\u001b[39mChrome(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchromedriver\u001b[39m\u001b[38;5;124m'\u001b[39m,options\u001b[38;5;241m=\u001b[39mchrome_options)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m host_about\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:455\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    442\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    247\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: disconnected: Unable to receive message from renderer\n  (failed to check if window was closed: timeout: Timed out receiving message from renderer: 600.000)\n  (Session info: headless chrome=108.0.5359.94)\nStacktrace:\n0   chromedriver                        0x0000000102a9ff38 chromedriver + 4910904\n1   chromedriver                        0x0000000102a1fa03 chromedriver + 4385283\n2   chromedriver                        0x0000000102664747 chromedriver + 472903\n3   chromedriver                        0x000000010264d427 chromedriver + 377895\n4   chromedriver                        0x000000010264d0a0 chromedriver + 376992\n5   chromedriver                        0x000000010264c2d6 chromedriver + 373462\n6   chromedriver                        0x000000010266da7d chromedriver + 510589\n7   chromedriver                        0x00000001026ea4da chromedriver + 1021146\n8   chromedriver                        0x00000001026ceee3 chromedriver + 909027\n9   chromedriver                        0x000000010269930c chromedriver + 688908\n10  chromedriver                        0x000000010269a88e chromedriver + 694414\n11  chromedriver                        0x0000000102a6d1de chromedriver + 4702686\n12  chromedriver                        0x0000000102a71b19 chromedriver + 4721433\n13  chromedriver                        0x0000000102a7928e chromedriver + 4752014\n14  chromedriver                        0x0000000102a7291a chromedriver + 4725018\n15  chromedriver                        0x0000000102a46b02 chromedriver + 4545282\n16  chromedriver                        0x0000000102a91888 chromedriver + 4851848\n17  chromedriver                        0x0000000102a91a05 chromedriver + 4852229\n18  chromedriver                        0x0000000102aa7e5f chromedriver + 4943455\n19  libsystem_pthread.dylib             0x00007ff81175e4f4 _pthread_start + 125\n20  libsystem_pthread.dylib             0x00007ff81175a00f thread_start + 15\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    new_parser = Parser(AIRBNB_LINK, './test.csv')\n",
    "    t0 = time.time()\n",
    "    new_parser.parse()\n",
    "    print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UWLZQrSefI8"
   },
   "source": [
    "credits @x-technology/airbnb-analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMfvZvjhefI9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvgbZkEvefI9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
