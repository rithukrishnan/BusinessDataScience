{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation of RV when distribution of RV is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture 2-3 LogRegression; Slide 8\n",
    "import numpy as np\n",
    "\n",
    "def expected_value(values, weights):\n",
    "    values = np.asarray(values)\n",
    "    weights = np.asarray(weights)\n",
    "    return (values * weights).sum() / weights.sum()\n",
    "\n",
    "#define values\n",
    "values = [0, 1, 2]\n",
    "\n",
    "#define probabilities\n",
    "probs  = [0.5, 0.25, .25]\n",
    "\n",
    "#calculate expected value\n",
    "expected_value(values, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When data is provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://machinelearningmastery.com/introduction-to-expected-value-variance-and-covariance/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 0.5 1. ]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Lecture 2-3 LogRegression; Slide 12\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "v = array([1.5, 0.5, 1])\n",
    "print(v)\n",
    "result = mean(v)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 0.5 1. ]\n",
      "0.25\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Lecture 2-3 LogRegression; Slide 12\n",
    "from numpy import array\n",
    "from numpy import var, std\n",
    "v = array([1.5, 0.5, 1])\n",
    "print(v)\n",
    "result = var(v, ddof=1)\n",
    "print(result)\n",
    "r_std = std(v, ddof=1)\n",
    "print(r_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[3.5 3.5]\n",
      "[1.87082869 1.87082869]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import var\n",
    "M = array([[1,2,3,4,5,6],[1,2,3,4,5,6]])\n",
    "print(M)\n",
    "col_mean = var(M, ddof=1, axis=0)\n",
    "print(col_mean)\n",
    "c_std = std(M, ddof=1, axis=0)\n",
    "print(c_std)\n",
    "row_mean = var(M, ddof=1, axis=1)\n",
    "print(row_mean)\n",
    "r_std = std(M, ddof=1, axis=1)\n",
    "print(r_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "[9 8 7 6 5 4 3 2 1]\n",
      "[[ 7.5 -7.5]\n",
      " [-7.5  7.5]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import cov\n",
    "x = array([1,2,3,4,5,6,7,8,9])\n",
    "print(x)\n",
    "y = array([9,8,7,6,5,4,3,2,1])\n",
    "print(y)\n",
    "# Covariance Matrix\n",
    "Sigma = cov(x,y)\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing covariance from samples\n",
    "### Cov matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3200.  3400.  4200. ]\n",
      " [3400.  3612.5 4462.5]\n",
      " [4200.  4462.5 5512.5]]\n",
      "[[ 25. -25.]\n",
      " [-25. 100.]]\n"
     ]
    }
   ],
   "source": [
    "# Lecture 2-3 LogRegression; Slide 17 --- Provided by professor\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "D= [ [80,160],[85,170],[75,180]]\n",
    "\n",
    "#convert to a data frame \n",
    "df = pd.DataFrame(D, columns = ['Weight', 'Height'])\n",
    "df.cov() \n",
    "\n",
    "dnp=np.array(D)   #this converts D into a numpy array \n",
    "print(np.cov(dnp))\n",
    "# vs\n",
    "print(np.cov(dnp.T))  #numpy treats rows as features unfortunately. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Project the vectors p1=[3,3,3]T,p2=[1,2,3]T and p3=[0,0,1] T on the subspace \u000b",
    "spanned by x1= [1,1,1] T, x2=[1,0,0]T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.11022302e-16  5.00000000e-01  5.00000000e-01]\n",
      " [ 1.00000000e+00 -5.00000000e-01 -5.00000000e-01]]\n",
      "[3.00000000e+00 3.33066907e-16]\n"
     ]
    }
   ],
   "source": [
    "# Lecture 2-3 LogRegression; Slide 22 --- Provided by professor\n",
    "# Projection P1\n",
    "import numpy as np\n",
    "\n",
    "xxinv= np.linalg.inv( [[3,1],[1,1]])\n",
    "\n",
    "x= np.array([[1,1,1],[1,0,0]]).T\n",
    "p1=np.array([3,3,3]).T\n",
    "projmat= np.matmul(xxinv, x.T)\n",
    "print(projmat)\n",
    "beta_star = np.matmul(projmat, p1)\n",
    "print(beta_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.11022302e-16  5.00000000e-01  5.00000000e-01]\n",
      " [ 1.00000000e+00 -5.00000000e-01 -5.00000000e-01]]\n",
      "[ 2.5 -1.5]\n"
     ]
    }
   ],
   "source": [
    "# Lecture 2-3 LogRegression; Slide 25 --- Provided by professor\n",
    "# Projection P2\n",
    "import numpy as np\n",
    "\n",
    "xxinv= np.linalg.inv( [[3,1],[1,1]])\n",
    "\n",
    "x= np.array([[1,1,1],[1,0,0]]).T\n",
    "p2=np.array([1,2,3]).T\n",
    "projmat= np.matmul(xxinv, x.T)\n",
    "print(projmat)\n",
    "beta_star = np.matmul(projmat, p2)\n",
    "print(beta_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.11022302e-16  5.00000000e-01  5.00000000e-01]\n",
      " [ 1.00000000e+00 -5.00000000e-01 -5.00000000e-01]]\n",
      "[ 0.5 -0.5]\n"
     ]
    }
   ],
   "source": [
    "# Lecture 2-3 LogRegression; Slide 26 --- Provided by professor\n",
    "# Projection P3\n",
    "import numpy as np\n",
    "\n",
    "xxinv= np.linalg.inv( [[3,1],[1,1]])\n",
    "\n",
    "x= np.array([[1,1,1],[1,0,0]]).T\n",
    "p3=np.array([0,0,1]).T\n",
    "projmat= np.matmul(xxinv, x.T)\n",
    "print(projmat)\n",
    "beta_star = np.matmul(projmat, p3)\n",
    "print(beta_star)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner product of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrices :\n",
      "x = [[2 3 4]\n",
      " [3 2 9]]\n",
      "\n",
      "y = [[ 1  5  0]\n",
      " [ 5 10  3]]\n",
      "\n",
      "Inner product of matrices x and y =\n",
      "[[17 52]\n",
      " [13 62]]\n"
     ]
    }
   ],
   "source": [
    "# Python Program illustrating\n",
    "# numpy.inner() method\n",
    "import numpy as np\n",
    "\n",
    "# Matrices\n",
    "x = np.array([[2, 3, 4], [3, 2, 9]])\n",
    "y = np.array([[1, 5, 0], [5, 10, 3]])\n",
    "print(\"\\nMatrices :\")\n",
    "print(\"x =\", x)\n",
    "print(\"\\ny =\", y)\n",
    "\n",
    "# Inner product of matrices\n",
    "print(\"\\nInner product of matrices x and y =\")\n",
    "print(np.inner(x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer Product of Vectors and Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors :\n",
      "a =  [2 6]\n",
      "\n",
      "b =  [ 3 10]\n",
      "\n",
      "Outer product of vectors a and b =\n",
      "[[ 6 20]\n",
      " [18 60]]\n",
      "------------------------------------\n",
      "\n",
      "Matrices :\n",
      "x = [[3 6 4]\n",
      " [9 4 6]]\n",
      "\n",
      "y = [[ 1 15  7]\n",
      " [ 3 10  8]]\n",
      "\n",
      "Outer product of matrices x and y =\n",
      "[[  3  45  21   9  30  24]\n",
      " [  6  90  42  18  60  48]\n",
      " [  4  60  28  12  40  32]\n",
      " [  9 135  63  27  90  72]\n",
      " [  4  60  28  12  40  32]\n",
      " [  6  90  42  18  60  48]]\n"
     ]
    }
   ],
   "source": [
    "# Python Program illustrating\n",
    "# numpy.outer() method\n",
    "import numpy as np\n",
    "\n",
    "# Vectors\n",
    "a = np.array([2, 6])\n",
    "b = np.array([3, 10])\n",
    "print(\"Vectors :\")\n",
    "print(\"a = \", a)\n",
    "print(\"\\nb = \", b)\n",
    "\n",
    "# Outer product of vectors\n",
    "print(\"\\nOuter product of vectors a and b =\")\n",
    "print(np.outer(a, b))\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Matrices\n",
    "x = np.array([[3, 6, 4], [9, 4, 6]])\n",
    "y = np.array([[1, 15, 7], [3, 10, 8]])\n",
    "print(\"\\nMatrices :\")\n",
    "print(\"x =\", x)\n",
    "print(\"\\ny =\", y)\n",
    "\n",
    "# Outer product of matrices\n",
    "print(\"\\nOuter product of matrices x and y =\")\n",
    "print(np.outer(x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Product of Vectors and Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors :\n",
      "a =  [3 6]\n",
      "\n",
      "b =  [ 9 10]\n",
      "\n",
      "Cross product of vectors a and b =\n",
      "-24\n",
      "------------------------------------\n",
      "\n",
      "Matrices :\n",
      "x = [[2 6 9]\n",
      " [2 7 3]]\n",
      "\n",
      "y = [[ 7  5  6]\n",
      " [ 3 12  3]]\n",
      "\n",
      "Cross product of matrices x and y =\n",
      "[[ -9  51 -32]\n",
      " [-15   3   3]]\n"
     ]
    }
   ],
   "source": [
    "# Python Program illustrating\n",
    "# numpy.cross() method\n",
    "import numpy as np\n",
    "\n",
    "# Vectors\n",
    "a = np.array([3, 6])\n",
    "b = np.array([9, 10])\n",
    "print(\"Vectors :\")\n",
    "print(\"a = \", a)\n",
    "print(\"\\nb = \", b)\n",
    "\n",
    "# Cross product of vectors\n",
    "print(\"\\nCross product of vectors a and b =\")\n",
    "print(np.cross(a, b))\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Matrices\n",
    "x = np.array([[2, 6, 9], [2, 7, 3]])\n",
    "y = np.array([[7, 5, 6], [3, 12, 3]])\n",
    "print(\"\\nMatrices :\")\n",
    "print(\"x =\", x)\n",
    "print(\"\\ny =\", y)\n",
    "\n",
    "# Cross product of matrices\n",
    "print(\"\\nCross product of matrices x and y =\")\n",
    "print(np.cross(x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection of a Vector on another vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection of Vector u on Vector v is:  [1.76923077 2.12307692 0.70769231]\n"
     ]
    }
   ],
   "source": [
    "# import numpy to perform operations on vector\n",
    "import numpy as np\n",
    "\n",
    "u = np.array([1, 2, 3]) # vector u\n",
    "v = np.array([5, 6, 2]) # vector v:\n",
    "\n",
    "# Task: Project vector u on vector v\n",
    "\n",
    "# finding norm of the vector v\n",
    "v_norm = np.sqrt(sum(v**2))\t\n",
    "\n",
    "# Apply the formula as mentioned above\n",
    "# for projecting a vector onto another vector\n",
    "# find dot product using np.dot()\n",
    "proj_of_u_on_v = (np.dot(u, v)/v_norm**2)*v\n",
    "\n",
    "print(\"Projection of Vector u on Vector v is: \", proj_of_u_on_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture 4-5 LogRegression; Slide 10\n",
    "from sklearn.metrics import mean_squared_error\n",
    "  \n",
    "# Given values\n",
    "Y_true = [80,20,30,10,70]  # Y_true = Y (original values)\n",
    "  \n",
    "# calculated values\n",
    "Y_pred = [90,40,30,40,100]  # Y_pred = Y'\n",
    "  \n",
    "# Calculation of Mean Squared Error (MSE)\n",
    "mean_squared_error(Y_true,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.2777777777777778\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Lecture 4-5 LogRegression; Slide 67\n",
    "def Ginx(P1,P2):\n",
    "    #P1 and P2 are the counts for each class after the split\n",
    "    denom = P1 + P2\n",
    "    Ginx = 2 * (P1/denom) * (P2/denom)\n",
    "    return(Ginx)\n",
    "\n",
    "print(Ginx(0,6))\n",
    "print(Ginx(1,5))\n",
    "print(Ginx(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.6500224216483541\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Lecture 4-5 LogRegression; Slide 67\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "\n",
    "def entropy_x(a):\n",
    "    return stats.entropy(a, base=2)\n",
    "\n",
    "print(entropy_x([0,6]))\n",
    "print(entropy_x([1,5]))\n",
    "print(entropy_x([3,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain based on Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07714\n"
     ]
    }
   ],
   "source": [
    "# Lecture 4-5 LogRegression; Slide 75\n",
    "# Calculate the gain of splitting on home ownership. [2 way split]\n",
    "\n",
    "S = [1, 0, 0, 1, 0, 0, 1, 0, 0, 0] # Actual table\n",
    "A = [0, 0, 0] # 1st split\n",
    "B = [0, 0, 1, 0, 1, 0, 1] # 2nd split\n",
    "\n",
    "def gini(p):\n",
    "    \"\"\"Gini impurity based on probability\"\"\"\n",
    "    return 2 * p * (1-p)\n",
    "\n",
    "def p(data):\n",
    "    \"\"\"Chance of success from bool array\"\"\"\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "giniS = gini(p(S))\n",
    "deltaA = gini(p(A)) * len(A) / len(S)\n",
    "deltaB = gini(p(B)) * len(B) / len(S)\n",
    "# If more splits add more deltas\n",
    "\n",
    "gain = giniS - deltaA - deltaB\n",
    "\n",
    "print(round(gain, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12\n"
     ]
    }
   ],
   "source": [
    "# Lecture 4-5 LogRegression; Slide 77\n",
    "# Calculate the gain of splitting on Marital Status (3 way split)\n",
    "\n",
    "S = [0,0,0,0,1,0,0,1,0,1] # Actual table\n",
    "A = [0,0,0,0] # 1st split\n",
    "B = [0,0,1,1] # 2nd split\n",
    "C = [1,0] # 3rd split\n",
    "\n",
    "def gini(p):\n",
    "    \"\"\"Gini impurity based on probability\"\"\"\n",
    "    return 2 * p * (1-p)\n",
    "\n",
    "def p(data):\n",
    "    \"\"\"Chance of success from bool array\"\"\"\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "giniS = gini(p(S))\n",
    "deltaA = gini(p(A)) * len(A) / len(S)\n",
    "deltaB = gini(p(B)) * len(B) / len(S)\n",
    "deltaC = gini(p(C)) * len(C) / len(S)\n",
    "\n",
    "gain = giniS - deltaA - deltaB - deltaC\n",
    "\n",
    "print(round(gain, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't have an exact code, so below code is for reference only. Snippets taken from this link:<br>\n",
    "https://datascience.stackexchange.com/questions/9262/calculating-kl-divergence-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1837868973868122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xd/8g2mv22d6h511dx9w5j2lfs80000gn/T/ipykernel_6180/3355768916.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  a = np.asarray(a, dtype=np.float)\n",
      "/var/folders/xd/8g2mv22d6h511dx9w5j2lfs80000gn/T/ipykernel_6180/3355768916.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  b = np.asarray(b, dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def KL(a, b):\n",
    "    a = np.asarray(a, dtype=np.float)\n",
    "    b = np.asarray(b, dtype=np.float)\n",
    "\n",
    "    return np.sum(np.where(a != 0, a * np.log(a / b), 0))\n",
    "\n",
    "\n",
    "values1 = [0.7,0.2,0.1]\n",
    "values2 = [0.4,0.4,0.2]\n",
    "\n",
    "print(KL(values1, values2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/cluster/_supervised.py:64: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and continuous values for target\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6365141682948129"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "sklearn.metrics.mutual_info_score([0.7,0.2,0.1],[0.4,0.4,0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01714783 0.04661262 0.93623955]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "# Lecture 9-11 LogRegression; Slide 19\n",
    "scores2D = np.array([1,2,5])\n",
    "\n",
    "# scores2D = np.array([[1, 2, 3, 6],\n",
    "#                      [2, 4, 5, 6],\n",
    "#                      [3, 8, 7, 6]])\n",
    "\n",
    "\n",
    "print(softmax(scores2D))\n",
    "# probabilities = softmax (scores) \n",
    "# Therefore below values are the probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
